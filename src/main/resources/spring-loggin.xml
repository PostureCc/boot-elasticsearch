<configuration>
    <!--设置系统日志目录-->
    <property name="APPDIR" value="logs/boot-elasticsearch"/>

    <!-- %m输出的信息,%p日志级别,%t线程名,%d日期,%c类的全名,%i索引【从数字0开始递增】,,, -->
    <!-- appender是configuration的子节点，是负责写日志的组件。 -->
    <!-- ConsoleAppender：把日志输出到控制台 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <!--            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} [%L] - %msg%n</pattern>-->
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] [%thread] %logger{50} [%L] - %msg%n</pattern>
            <!-- 控制台也要使用UTF-8，不要使用GBK，否则会中文乱码 -->
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <appender name="ERROR_FILE"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <File>${APPDIR}/error.log</File>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <!-- rollingPolicy:当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名。 -->
        <!-- TimeBasedRollingPolicy： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志归档 -->
            <fileNamePattern>${APPDIR}/error_%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>100MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <!--日志文件保留天数-->
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <!-- pattern节点，用来设置日志的输入格式 -->
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] [%thread] %logger{50} [%L] - %msg%n</pattern>
            <!-- 记录日志的编码 -->
            <charset>UTF-8</charset> <!-- 此处设置字符集 -->
        </encoder>
    </appender>
    <appender name="ERROR_ASYNC" class="ch.qos.logback.classic.AsyncAppender">        
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->        
        <discardingThreshold>0</discardingThreshold>        
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->        
        <queueSize>256</queueSize>        
        <!-- 添加附加的appender,最多只能添加一个 -->        
        <appender-ref ref="ERROR_FILE"/>    
    </appender>

    <!-- RollingFileAppender：滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 -->
    <!-- 以下的大概意思是：1.先按日期存日志，日期变了，将前一天的日志文件名重命名为XXX%日期%索引，新的日志仍然是sys.log -->
    <!--             2.如果日期没有发生变化，但是当前日志的文件大小超过1KB时，对当前日志进行分割 重命名-->
    <appender name="DEBUG_FILE"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <File>${APPDIR}/debug.log</File>
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>DEBUG</level>
        </filter>
        <!-- rollingPolicy:当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名。 -->
        <!-- TimeBasedRollingPolicy： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志归档 -->
            <fileNamePattern>${APPDIR}/debug_%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>100MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <!--日志文件保留天数-->
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <!-- pattern节点，用来设置日志的输入格式 -->
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] [%thread] %logger{50} [%L] - %msg%n</pattern>
            <!-- 记录日志的编码 -->
            <charset>UTF-8</charset> <!-- 此处设置字符集 -->
        </encoder>
    </appender>
    <appender name="DEBUG_ASYNC" class="ch.qos.logback.classic.AsyncAppender">        
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->        
        <discardingThreshold>0</discardingThreshold>        
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->        
        <queueSize>256</queueSize>        
        <!-- 添加附加的appender,最多只能添加一个 -->        
        <appender-ref ref="DEBUG_FILE"/>    
    </appender>

    <!--将日志输出到Logstash-->
<!--    <appender name="STASH"-->
<!--              class="net.logstash.logback.appender.LogstashTcpSocketAppender">-->
<!--        <destination>JD:4560</destination>-->

<!--        &lt;!&ndash; encoder is required &ndash;&gt;-->
<!--        <encoder class="net.logstash.logback.encoder.LogstashEncoder"/>-->
<!--    </appender>-->

<!--    <appender name="KAFKA_APPENDER" class="com.github.danielwegener.logback.kafka.KafkaAppender">-->
<!--        <encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder" >-->
<!--            <customFields>{"pojoName":"boot-elasticsearch"}</customFields>-->
<!--            <includeMdc>true</includeMdc>-->
<!--            <includeContext>true</includeContext>-->
<!--            <throwableConverter class="net.logstash.logback.stacktrace.ShortenedThrowableConverter">-->
<!--                <maxDepthPerThrowable>30</maxDepthPerThrowable>-->
<!--                <rootCauseFirst>true</rootCauseFirst>-->
<!--            </throwableConverter>-->
<!--        </encoder>-->
<!--        <topic>filebeat-topic-test</topic>-->
<!--        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />-->
<!--        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />-->
<!--        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.BlockingDeliveryStrategy">-->
<!--            &lt;!&ndash; wait indefinitely until the kafka producer was able to send the message &ndash;&gt;-->
<!--            <timeout>0</timeout>-->
<!--        </deliveryStrategy>-->
<!--        <producerConfig>bootstrap.servers=jd:9092</producerConfig>-->
<!--        &lt;!&ndash; don't wait for a broker to ack the reception of a batch.  &ndash;&gt;-->
<!--        <producerConfig>acks=0</producerConfig>-->
<!--        &lt;!&ndash; wait up to 1000ms and collect log messages before sending them as a batch &ndash;&gt;-->
<!--        <producerConfig>linger.ms=1000</producerConfig>-->
<!--        &lt;!&ndash; even if the producer buffer runs full, do not block the application but start to drop messages &ndash;&gt;-->
<!--        <producerConfig>max.block.ms=0</producerConfig>-->
<!--        <appender-ref ref="CONSOLE" />-->
<!--    </appender>-->

    <!-- 控制台输出日志级别 -->
    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="DEBUG_FILE"/>
        <appender-ref ref="ERROR_FILE"/>
<!--        <appender-ref ref="STASH"/>-->
<!--        <appender-ref ref="KAFKA_APPENDER"/>-->
    </root>
    <!-- 指定项目中某个包，当有日志操作行为时的日志记录级别 -->
    <!-- com.appley为根包，也就是只要是发生在这个根包下面的所有日志操作行为的权限都是DEBUG -->
    <!-- 级别依次为【从高到低】：FATAL > ERROR > WARN > INFO > DEBUG > TRACE  -->
    <!--    <logger name="com.appleyk" level="DEBUG">-->
    <!--        <appender-ref ref="syslog"/>-->
    <!--    </logger>-->
</configuration>